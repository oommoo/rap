# File Format V2 WIP

New and improved file format.  

## Goals

 * Variable precision. If someone needs the highest precision possible, that's fine. If they don't, we can save them massive space.
 * Support Eye Tracking.
   * Another way of putting it: Allow people to build their own "thing" to record. Don't limit them to Unity GameObjects.
 * Support arbitrary binaries (to support things like audio), associate binaries with specific subject/group. Binaries need to also be able to have "lengths" associated with them, and when they start
 * Support more complex curves for fitting captured values too (Somehow incorporate bezier?).
 * Support Groupings of Subjects
   * A great way of organizing things. Can group all "enemies" in one capture at a certain frame rate, and all things about the player in another grouping (Headset, right hand, and left hand)
 * *Potentially*: Be able to support different "resolutions" in some form or fashion.
 * *Potentially*: Support recording traditional animations?

## Definitions

* **Capture** - Data associated with a specific point in time
* **Capture Stream** - A collection of *Captures* around a specific type of data (think something like positional data). We can build many fundamental streams for people to use immediately: Vector3, float, int, dictionary, etc.
* **Subject** - A collection of *Capture Streams*. In V2 this collection is no longer set in stone (currently it's just position, rotation, custom, and lifecycle). In this new format, a subject can be composed of any number of streams. If there's no need to capture something like position, then why bother? Also, if I want to capture something like where a player is looking, why not make it easy to tack on to the player subject?
* ~~**Crowd** - A collection of *Subjects*. In V1 this is simply a recording. Ideally, we'd be able to configure multiple groups in a single recording for V2 to enhance organizational abilities. With that, we could do cute things like setting different frame rates depending on the crowd a subject is apart of.~~
  * 
* **Recording** - A collection of Subjects.

### MF Extra Stuff That Will Put Us In a New Dimension

* Examining ranges of values, adjusting bytes used to store a value.
  * If we know a certain value is within the range of [-1, 1], then there is no need to use 4 whole bytes to represent it (at least for most applications). We could get "good enough" accuracy by simply using something like 2 bytes (or even 1). If we extend this concept to something like a [unit vector](https://mathworld.wolfram.com/UnitVector.html#:~:text=A%20unit%20vector%20is%20a,as%20the%20(finite)%20vector%20.) (what will be used for gaze tracking and normals, we could potentially reduce a capture from taking up 12 bytes to taking up 6. This could be implemented on a per Capture Stream basis.
  * You can see this method being used for [Original Crash Bandicoot animations](https://www.youtube.com/watch?v=izxXGuVL21o) (Skip to 18:25)
* Knowing when to put a Vector3 to a texture (extremely beneficial for playback using GPU). This requires texture to be POT ideally for maximum playback
* Utilizing unit vectors as much as possible, since we now have methods for major compression.
* Area of research: Curve fitting.
  * One solution is Ramer–Douglas–Peucker algorithm
* Look into SQUISH

## Binary File Spec

### Common Binary Patterns

Common patterns you'll see throughout the document.

* [varint] - variable sized uint64. Only takes up 1 byte if only one byte is needed.
* [string] - varint representing number of characters in string, followed by string itself.

### Outline

The overall outline of the file just consists of version, header, and body. The header will always be uncompressed, and the body will always be compressed.

 * [1 byte]  - uint8: major version number (2)
 * [4 bytes] - uint32: size of header
 * [n bytes] - header
 * [4 bytes] - uint32: size of body
 * [n bytes] - body

### Header

Contains a bunch of meta information about what the recording is, never compressed.

* [1 byte] - uint8: header version
* V1
  * [string]  - recording name
  * [4 bytes] - float32: recording start time
  * [4 bytes] - float32: recording end time
  * [varint]  - number of subjects in recording
  * [varint] - number of metadata entries (key value pairs)
  * [n*2 string] - two strings per metadata entry.

### Body

The body is inspired by formats like APK, .unitypackage, nuget, etc that have to keep up with multiple different types of data within. The ZIP format seems like a perfect choice to provide structure, open ease of use by other people, and extensibility. 

* [1 byte] uint8: header version (uncompressed)
* V1
  * A ZIP file

```
V1 ZIP Folder Structure
├── global
│   ├── data
│   │   └── thumbnail.png
│   └── streams
│       └── custom-event
├── keys
│   ├── metadata
│   └── tags
└── subjects
    ├── 102932571
    │   ├── info
    │   └── streams
    │       ├── gaze
    │       ├── lifecycle
    │       ├── position
    │       └── rotation
    └── 482073950
        ├── data
        │   └── audio.mp3
        ├── info
        └── streams
            ├── custom-event
            ├── lifecycle
            └── rotation
```

## Working Notes

As I research compression, I'm not sure how much savings we'll get being super smart about float ranges VS just always zipping the data up. I think the real reason we want float ranges would be for proper streaming/quality specification (420p vs 1080), which is desirable in its own right. Even continuous entropy uses the concept of binning, which makes me think "round to nearest X decimal places". 

Many compression methods assume all events are independent of each other. While this can still be the case for an object's position (worse case scenario is an object teleporting around randomly, which I can't think of an example in gamedev), this is not the case with time. Perhaps we can look into methods for compression our timestamps. Bonus points if we can make what we send over variable to the type of quality/accuracy requested. Since time is monotonic, and always greater than 0, I feel like we can probably widdle that bitch down to under a byte.

The more I think about it, the more we need a seperate protocol for streaming. This file format can't be the end all be all.

### Resources to Explore

https://blog.acolyer.org/2016/05/03/gorilla-a-fast-scalable-in-memory-time-series-database/

https://dl.acm.org/doi/10.1145/3264903

Ramer–Douglas–Peucker algorithm

[SQUISH](http://www.cs.albany.edu/~jhh/publications/muckell.com.geo10.squish.pdf) in general

TD-TR Alrorithm

Open Window Algorithm